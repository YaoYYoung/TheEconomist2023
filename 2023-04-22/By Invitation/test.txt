{"props":{"pageProps":{"readerId":"440d4fc9-023c-57f9-8e66-c849e41f96b5","contactId":"","pageUrl":"https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts","domain":"https://www.economist.com","auth":{"loggedIn":true,"verified":false,"isAnonymous":true,"isSubscriber":false,"bulkSubscriber":false,"userType":"anonymous"},"pageType":"ARTICLE","isSubscriber":false,"region":"JP","content":{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts","__typename":"URL"},"__typename":"Content","id":"/content/97rviamdk8sorcopa3sr5botkn06oo7d","tegID":"97rviamdk8sorcopa3sr5botkn06oo7d","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"The world needs an international agency for artificial intelligence, say two AI experts","subheadline":"Artificial intelligence","seoPageTitle":null,"seoMetadataDescription":null,"ad":{"grapeshot":{"channels":[{"name":"gv_safe","score":23468.25,"__typename":"GrapeshotChannel"},{"name":"future_of_work_test","score":4.457,"__typename":"GrapeshotChannel"},{"name":"gs_tech","score":3.55,"__typename":"GrapeshotChannel"},{"name":"gs_tech_computing","score":3.122,"__typename":"GrapeshotChannel"},{"name":"chanel_neg","score":2.805,"__typename":"GrapeshotChannel"},{"name":"gt_negative","score":2.706,"__typename":"GrapeshotChannel"},{"name":"ibm_cloud","score":2.375,"__typename":"GrapeshotChannel"},{"name":"gs_politics","score":2.276,"__typename":"GrapeshotChannel"},{"name":"neg_omd_exclusion","score":2.013,"__typename":"GrapeshotChannel"},{"name":"neg_morgan_stanley_2019_neg_keywords","score":2.011,"__typename":"GrapeshotChannel"},{"name":"test","score":1.995,"__typename":"GrapeshotChannel"},{"name":"gs_tech_ai","score":1.971,"__typename":"GrapeshotChannel"},{"name":"neg_ey_kwbl","score":1.884,"__typename":"GrapeshotChannel"},{"name":"neg_3166_vca_brand-safety","score":1.857,"__typename":"GrapeshotChannel"},{"name":"neg_3166_vca_brand-safety3","score":1.857,"__typename":"GrapeshotChannel"},{"name":"gs_busfin","score":1.743,"__typename":"GrapeshotChannel"},{"name":"neg_facebook","score":1.737,"__typename":"GrapeshotChannel"},{"name":"ibm_blacklist","score":1.721,"__typename":"GrapeshotChannel"},{"name":"artificial_intelligence","score":1.692,"__typename":"GrapeshotChannel"},{"name":"neg_ey_brandsafety","score":1.594,"__typename":"GrapeshotChannel"},{"name":"cigna_healthyhybridworkplace","score":1.584,"__typename":"GrapeshotChannel"},{"name":"asia_nec_technology","score":1.553,"__typename":"GrapeshotChannel"},{"name":"gs_science_misc","score":1.509,"__typename":"GrapeshotChannel"},{"name":"ts_tech","score":1.5,"__typename":"GrapeshotChannel"},{"name":"fow_barclays","score":1.476,"__typename":"GrapeshotChannel"},{"name":"america_nanny_state","score":1.433,"__typename":"GrapeshotChannel"},{"name":"google_negative_keywords","score":1.418,"__typename":"GrapeshotChannel"},{"name":"custom_punkt","score":1.412,"__typename":"GrapeshotChannel"},{"name":"legal_law","score":1.412,"__typename":"GrapeshotChannel"},{"name":"neg_ibm_brandsafety","score":1.351,"__typename":"GrapeshotChannel"},{"name":"business_it_decisionmakers","score":1.318,"__typename":"GrapeshotChannel"},{"name":"cigna_puttingfamilyfirst","score":1.259,"__typename":"GrapeshotChannel"},{"name":"future_of_work","score":1.241,"__typename":"GrapeshotChannel"},{"name":"neg_google_youtube_2020","score":1.22,"__typename":"GrapeshotChannel"},{"name":"test_mba","score":1.201,"__typename":"GrapeshotChannel"},{"name":"gs_law","score":1.198,"__typename":"GrapeshotChannel"},{"name":"america_department_security","score":1.179,"__typename":"GrapeshotChannel"},{"name":"neg_huawei_brandsafety","score":1.171,"__typename":"GrapeshotChannel"},{"name":"gs_tech_robotics","score":1.146,"__typename":"GrapeshotChannel"},{"name":"gs_education","score":1.117,"__typename":"GrapeshotChannel"},{"name":"fidelity_blacklist","score":1.113,"__typename":"GrapeshotChannel"},{"name":"america_campaigns_elections","score":1.094,"__typename":"GrapeshotChannel"},{"name":"gs_business","score":1.093,"__typename":"GrapeshotChannel"},{"name":"gt_negative_fear","score":1.028,"__typename":"GrapeshotChannel"},{"name":"gs_politics_issues_policy","score":1.025,"__typename":"GrapeshotChannel"},{"name":"america_department_education","score":1.001,"__typename":"GrapeshotChannel"},{"name":"thought_leader","score":0.989,"__typename":"GrapeshotChannel"},{"name":"neg_cartier","score":0.941,"__typename":"GrapeshotChannel"},{"name":"america_department_commerce","score":0.923,"__typename":"GrapeshotChannel"},{"name":"ge_tech_enthusiasts","score":0.921,"__typename":"GrapeshotChannel"},{"name":"gt_negative_mistrust","score":0.919,"__typename":"GrapeshotChannel"},{"name":"america_supreme_court","score":0.863,"__typename":"GrapeshotChannel"},{"name":"gs_politics_misc","score":0.862,"__typename":"GrapeshotChannel"},{"name":"gs_busfin_indus","score":0.856,"__typename":"GrapeshotChannel"},{"name":"gt_positive_curiosity","score":0.841,"__typename":"GrapeshotChannel"},{"name":"hsbc_sustainability","score":0.828,"__typename":"GrapeshotChannel"},{"name":"neg_mediakitchen_gs","score":0.822,"__typename":"GrapeshotChannel"},{"name":"america_department_justice","score":0.817,"__typename":"GrapeshotChannel"},{"name":"neg_exxon","score":0.812,"__typename":"GrapeshotChannel"},{"name":"neg_dit9","score":0.769,"__typename":"GrapeshotChannel"},{"name":"gs_politics_elections","score":0.764,"__typename":"GrapeshotChannel"},{"name":"microsoft_blacklist","score":0.762,"__typename":"GrapeshotChannel"},{"name":"neg_ey","score":0.753,"__typename":"GrapeshotChannel"},{"name":"neg_dit","score":0.748,"__typename":"GrapeshotChannel"},{"name":"it_decisionmakers","score":0.73,"__typename":"GrapeshotChannel"}],"__typename":"Grapeshot"},"__typename":"Ad"},"audio":{"main":null,"__typename":"Media"},"image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230418_BID001.jpg","__typename":"URL"},"__typename":"Content","height":720,"width":1280,"description":""},"promo":null,"__typename":"Media"},"description":"Gary Marcus and Anka Reuel argue that global governance must be prioritised to address the risks of bias, misinformation or worse","datePublished":"2023-04-18T20:20:24Z","dateModified":"2023-04-20T16:59:35Z","dateModifiedString":"Apr 20th 2023","datePublishedString":"Apr 18th 2023","dateCreated":"2023-04-18T20:20:12Z","copyrightYear":2023,"inLanguage":"en","byline":"","dateline":null,"text":[{"type":"tag","name":"p","attribs":{},"children":[{"type":"tag","name":"span","attribs":{"data-caps":"initial"},"children":[{"data":"N","type":"text"}]},{"type":"tag","name":"small","attribs":{},"children":[{"data":"EW GENERATIVE-AI","type":"text"}]},{"data":" tools like Open","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":"’s Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":", the fastest-growing consumer internet application of all time, have taken the world by storm. They have uses in everything from education to medicine and are astonishingly fun to play with. Although current","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":" AI","type":"text"}]},{"data":" systems are capable of spectacular feats they also carry risks. Europol has warned that they might greatly increase cybercrime. Many ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" experts are deeply worried about their potential to create a tsunami of misinformation, posing an imminent threat to the American presidential election in 2024, and ultimately to democracy itself, by creating an atmosphere of total distrust. Scientists have warned that these new tools could be used to design novel, deadly toxins. Others speculate that in the long term there could be a genuine ","type":"text"},{"type":"tag","name":"a","attribs":{"href":"https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI_AI-Index-Report_2023.pdf"},"children":[{"data":"risk to humanity itself","type":"text"}]},{"data":". ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"One of the key issues with current ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" systems is that they are primarily black boxes, often unreliable and hard to interpret, and at risk of getting out of control. For example, the core technology underlying systems like Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":", large language models (","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"LLMs","type":"text"}]},{"data":"), is known to “hallucinate”, making up false statements. Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":", for example, falsely accused a law professor of being involved in sexual harassment, apparently confused by statistical but irrelevant connections between bits of text that didn’t actually belong together. After an op-ed tried to clarify what had gone wrong, Bing Chat made a similar error, and attributed it to information in ","type":"text"},{"type":"tag","name":"i","attribs":{},"children":[{"type":"tag","name":"small","attribs":{},"children":[{"data":"USA","type":"text"}]},{"data":" Today","type":"text"}]},{"data":" that the chatbot got completely backwards. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"These systems can also be used for deliberate abuse, from disrupting elections (for example by manipulating what candidates appear to say or write) to spreading medical misinformation. In a recent analysis of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":"-4, Open","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":"’s most advanced","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":" LLM","type":"text"}]},{"data":", the company acknowledged 12 serious concerns—without providing firm solutions to any of them. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"In the past year alone 37 regulations mentioning ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI ","type":"text"}]},{"data":"were passed around the globe; Italy went so far as to ban Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT.","type":"text"}]},{"data":" But there is little global co-ordination. Even within some countries there is a hodge-podge, such as different state laws in America, or Britain’s proposal to eschew a central regulator, leaving oversight split among several agencies. An uneven, loophole-ridden patchwork is to no one’s benefit and safety. Nor should companies want to build a different ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI ","type":"text"}]},{"data":"model for each jurisdiction and face their own de novo struggle to navigate legal, cultural and social contexts. ","type":"text"}]},{"type":"tag","name":"aside","attribs":{},"children":[{"type":"tag","name":"p","attribs":{},"children":[{"data":"Read more from our special series on ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":":","type":"text"}]},{"type":"tag","name":"ul","attribs":{},"children":[{"type":"tag","name":"li","attribs":{},"children":[{"type":"tag","name":"a","attribs":{"href":"https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work","data-tegid":"ad0pj0210lp3qhpd542inu4ti4vfs27o"},"children":[{"data":"Large, creative ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" models will transform lives and labour markets","type":"text"}]}]},{"type":"tag","name":"li","attribs":{},"children":[{"type":"tag","name":"a","attribs":{"href":"https://www.economist.com/science-and-technology/2023/04/19/how-generative-models-could-go-wrong"},"children":[{"data":"How generative models could go wrong","type":"text"}]}]},{"type":"tag","name":"li","attribs":{},"children":[{"type":"tag","name":"a","attribs":{"href":"https://www.economist.com/science-and-technology/2023/04/19/large-language-models-ability-to-generate-text-also-lets-them-plan-and-reason"},"children":[{"data":"Large language models’ ability to generate text also lets them plan and reason","type":"text"}]}]}]}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"Still, there is plenty of agreement about basic responsible ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" principles, such as safety and reliability, transparency, explainability, interpretability, privacy, accountability and fairness. And almost everyone agrees that something must be done—a ","type":"text"},{"type":"tag","name":"a","attribs":{"href":"https://www.governance.ai/post/increasing-consensus-ai-requires-careful-management"},"children":[{"data":"just-published poll","type":"text"}]},{"data":" by the Centre for the Governance of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" found that 91% of a representative sample of 13,000 people across 11 countries agreed that","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":" AI","type":"text"}]},{"data":" needs to be carefully managed. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"It is in this context that we call for the immediate development of a global, neutral, non-profit International Agency for","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":" AI","type":"text"}]},{"data":" (","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"IAAI","type":"text"}]},{"data":"), with guidance and buy-in from governments, large technology companies, non-profits, academia and society at large, aimed at collaboratively finding governance and technical solutions to promote safe, secure and peaceful ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI ","type":"text"}]},{"data":"technologies. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"The time for such an agency has come, as Google ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"CEO","type":"text"}]},{"data":" Sundar Pichai himself said on April 16th. What might that look like? Each domain and each industry will be different, with its own set of guidelines, but many will involve both global governance and technological innovation. For example, people have long agreed that making employment decisions based on gender should be avoided, and have even come up with some measures in earlier, more interpretable ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":", such as the interpretability requirements of the ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" Bill of Rights proposed by the Biden administration. But in black-box systems like Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":" there is a wide variety of use cases with no current remedy. People might, for example, feed in a job candidate’s entire file and ask Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":" for a judgment, but we currently have no way to ensure that Chat","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":" would avoid bias in its output. The kind of entity we envision would collaboratively address what to do about such “off-label” uses of chatbots and other policy questions, and at the same time develop technical tools for effective auditing. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"The ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"IAAI","type":"text"}]},{"data":" could likewise convene experts and develop tools to tackle the spread of misinformation. On the policy side, it could ask, for instance, how wide-scale spreading of misinformation might be penalised. On the technical side, the initial focus should be on developing automated or semi-automated tools for answering fundamental questions, such as “How much misinformation is out there?”, “How rapidly is its volume growing?” and “How much is ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" contributing to such problems?” Existing technologies are better at generating misinformation than detecting it. Considerable technical innovation will be required, and of great public benefit, but may or may not be of sufficiently direct commercial interest – hence the need for independent support by an entity like the ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"IAAI","type":"text"}]},{"data":". ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"To take a third, very recent example, systems with names like Auto","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GPT","type":"text"}]},{"data":" and Baby","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AGI","type":"text"}]},{"data":" have been devised that allow amateurs to build complex and difficult-to-debug (or even fathom) assemblies of unreliable ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" systems controlling other unreliable ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" systems to achieve arbitrary goals—a practice that may or may not prove to be safe. As Marek Rosa, ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"CEO","type":"text"}]},{"data":" of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"GOOD","type":"text"}]},{"data":".Ai, put it, we need new technical ideas on “how to increase security (proactive defence) in a world where there are billions of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI ","type":"text"}]},{"data":"agents…running in apps and servers, and we don’t know what they are talking about”, perhaps necessitating a kind of “antivirus [software] against ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" agents”. A global alliance with top experts and researchers on call would be able to give swift and thoughtful guidance on such new developments. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"Designing the kind of global collaboration we envision is an enormous job. Many stakeholders need to be involved. Both short-term and long-term risks must be considered. No solution is going to succeed unless both governments and companies are on board, and it’s not just them: the world’s publics need a seat at the table. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"Fortunately, there is precedent for such global co-operation. At the end of the second world war, for example, nuclear weapons sparked deep fears and uncertainties about how the new technology would be used. As a response, 81 countries unanimously approved the International Atomic Energy Agency’s statute to “promote safe, secure and peaceful nuclear technologies”, with inspection rights. A different, softer kind of model, with less focus on enforcement, is the International Civil Aviation Organisation, in which member countries make their own laws but take counsel from a global agency. Getting to the right model, and making the right choices, will take time, wisdom and collaboration. ","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"The challenges and risks of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI","type":"text"}]},{"data":" are, of course, very different and, to a disconcerting degree, still unknown. We know in hindsight that the internet might have been designed in better ways with more forethought. Earlier decisions about how to handle privacy and anonymity, for instance, might have ensured that there was less of a culture of trolling. We also know that early choices get locked in. Our decisions now are likely to have lasting consequences and must be made thoughtfully.","type":"text"}]},{"type":"tag","name":"p","attribs":{},"children":[{"data":"Given how fast things are moving, there is not a lot of time to waste. A global, neutral non-profit with support from governments, big business and society is an important start. ","type":"text"},{"type":"tag","name":"span","attribs":{"data-ornament":"ufinish"},"children":[{"data":"■","type":"text"}]}]},{"type":"tag","name":"p","attribs":{},"children":[{"type":"tag","name":"i","attribs":{},"children":[{"data":"Gary Marcus is Emeritus Professor at NYU and was founder and ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"CEO ","type":"text"}]},{"data":"of Geometric Intelligence, a machine-learning company acquired by Uber. Anka Reuel is a PhD student in computer science at Stanford University and founding member of ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"KIRA","type":"text"}]},{"data":", a think-tank focusing on the promotion of responsible ","type":"text"},{"type":"tag","name":"small","attribs":{},"children":[{"data":"AI.","type":"text"}]}]}]}],"bodyText":"NEW GENERATIVE-AI tools like OpenAI’s ChatGPT, the fastest-growing consumer internet application of all time, have taken the world by storm. They have uses in everything from education to medicine and are astonishingly fun to play with. Although current AI systems are capable of spectacular feats they also carry risks. Europol has warned that they might greatly increase cybercrime. Many AI experts are deeply worried about their potential to create a tsunami of misinformation, posing an imminent threat to the American presidential election in 2024, and ultimately to democracy itself, by creating an atmosphere of total distrust. Scientists have warned that these new tools could be used to design novel, deadly toxins. Others speculate that in the long term there could be a genuine risk to humanity itself. \nOne of the key issues with current AI systems is that they are primarily black boxes, often unreliable and hard to interpret, and at risk of getting out of control. For example, the core technology underlying systems like ChatGPT, large language models (LLMs), is known to “hallucinate”, making up false statements. ChatGPT, for example, falsely accused a law professor of being involved in sexual harassment, apparently confused by statistical but irrelevant connections between bits of text that didn’t actually belong together. After an op-ed tried to clarify what had gone wrong, Bing Chat made a similar error, and attributed it to information in USA Today that the chatbot got completely backwards. \nThese systems can also be used for deliberate abuse, from disrupting elections (for example by manipulating what candidates appear to say or write) to spreading medical misinformation. In a recent analysis of GPT-4, OpenAI’s most advanced LLM, the company acknowledged 12 serious concerns—without providing firm solutions to any of them. \nIn the past year alone 37 regulations mentioning AI were passed around the globe; Italy went so far as to ban ChatGPT. But there is little global co-ordination. Even within some countries there is a hodge-podge, such as different state laws in America, or Britain’s proposal to eschew a central regulator, leaving oversight split among several agencies. An uneven, loophole-ridden patchwork is to no one’s benefit and safety. Nor should companies want to build a different AI model for each jurisdiction and face their own de novo struggle to navigate legal, cultural and social contexts. \nRead more from our special series on AI:\nLarge, creative AI models will transform lives and labour markets\nHow generative models could go wrong\nLarge language models’ ability to generate text also lets them plan and reason\n\n\nStill, there is plenty of agreement about basic responsible AI principles, such as safety and reliability, transparency, explainability, interpretability, privacy, accountability and fairness. And almost everyone agrees that something must be done—a just-published poll by the Centre for the Governance of AI found that 91% of a representative sample of 13,000 people across 11 countries agreed that AI needs to be carefully managed. \nIt is in this context that we call for the immediate development of a global, neutral, non-profit International Agency for AI (IAAI), with guidance and buy-in from governments, large technology companies, non-profits, academia and society at large, aimed at collaboratively finding governance and technical solutions to promote safe, secure and peaceful AI technologies. \nThe time for such an agency has come, as Google CEO Sundar Pichai himself said on April 16th. What might that look like? Each domain and each industry will be different, with its own set of guidelines, but many will involve both global governance and technological innovation. For example, people have long agreed that making employment decisions based on gender should be avoided, and have even come up with some measures in earlier, more interpretable AI, such as the interpretability requirements of the AI Bill of Rights proposed by the Biden administration. But in black-box systems like ChatGPT there is a wide variety of use cases with no current remedy. People might, for example, feed in a job candidate’s entire file and ask ChatGPT for a judgment, but we currently have no way to ensure that ChatGPT would avoid bias in its output. The kind of entity we envision would collaboratively address what to do about such “off-label” uses of chatbots and other policy questions, and at the same time develop technical tools for effective auditing. \nThe IAAI could likewise convene experts and develop tools to tackle the spread of misinformation. On the policy side, it could ask, for instance, how wide-scale spreading of misinformation might be penalised. On the technical side, the initial focus should be on developing automated or semi-automated tools for answering fundamental questions, such as “How much misinformation is out there?”, “How rapidly is its volume growing?” and “How much is AI contributing to such problems?” Existing technologies are better at generating misinformation than detecting it. Considerable technical innovation will be required, and of great public benefit, but may or may not be of sufficiently direct commercial interest – hence the need for independent support by an entity like the IAAI. \nTo take a third, very recent example, systems with names like AutoGPT and BabyAGI have been devised that allow amateurs to build complex and difficult-to-debug (or even fathom) assemblies of unreliable AI systems controlling other unreliable AI systems to achieve arbitrary goals—a practice that may or may not prove to be safe. As Marek Rosa, CEO of GOOD.Ai, put it, we need new technical ideas on “how to increase security (proactive defence) in a world where there are billions of AI agents…running in apps and servers, and we don’t know what they are talking about”, perhaps necessitating a kind of “antivirus [software] against AI agents”. A global alliance with top experts and researchers on call would be able to give swift and thoughtful guidance on such new developments. \nDesigning the kind of global collaboration we envision is an enormous job. Many stakeholders need to be involved. Both short-term and long-term risks must be considered. No solution is going to succeed unless both governments and companies are on board, and it’s not just them: the world’s publics need a seat at the table. \nFortunately, there is precedent for such global co-operation. At the end of the second world war, for example, nuclear weapons sparked deep fears and uncertainties about how the new technology would be used. As a response, 81 countries unanimously approved the International Atomic Energy Agency’s statute to “promote safe, secure and peaceful nuclear technologies”, with inspection rights. A different, softer kind of model, with less focus on enforcement, is the International Civil Aviation Organisation, in which member countries make their own laws but take counsel from a global agency. Getting to the right model, and making the right choices, will take time, wisdom and collaboration. \nThe challenges and risks of AI are, of course, very different and, to a disconcerting degree, still unknown. We know in hindsight that the internet might have been designed in better ways with more forethought. Earlier decisions about how to handle privacy and anonymity, for instance, might have ensured that there was less of a culture of trolling. We also know that early choices get locked in. Our decisions now are likely to have lasting consequences and must be made thoughtfully.\nGiven how fast things are moving, there is not a lot of time to waste. A global, neutral non-profit with support from governments, big business and society is an important start. ■\nGary Marcus is Emeritus Professor at NYU and was founder and CEO of Geometric Intelligence, a machine-learning company acquired by Uber. Anka Reuel is a PhD student in computer science at Stanford University and founding member of KIRA, a think-tank focusing on the promotion of responsible AI.","about":{"public":null,"__typename":"Taxonomies"},"print":{"headline":"The world needs an international agency for artificial intelligence, say two AI experts","section":{"url":{"canonical":"https://www.economist.com/by-invitation/","__typename":"URL"},"__typename":"Content","headline":"By Invitation"},"__typename":"Print"},"articleSection":{"public":null,"internal":[{"url":{"canonical":"https://www.economist.com/by-invitation/","__typename":"URL"},"__typename":"Content","id":"/content/arf6v6apbfv7pa17gm9ipjqoulhgsg79","tegID":"arf6v6apbfv7pa17gm9ipjqoulhgsg79","headline":"By Invitation","hasPart":{"parts":[{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/19/only-a-sustained-fall-in-oil-prices-will-break-vladimir-putins-regime-argues-kirill-rogov","__typename":"URL"},"__typename":"Content","id":"/content/bf7p309sks2ro7g6rp29g80boshuln7t","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"Only a sustained fall in oil prices will break Vladimir Putin’s regime, argues Kirill Rogov","subheadline":"Putin’s Achilles heel","datePublished":"2023-04-19T13:49:52Z","description":"The political scientist says that sanctions have had a big economic impact, but energy revenues have dulled the pain","image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20221008_BID001.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":720},"__typename":"Media","promo":null}},{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts","__typename":"URL"},"__typename":"Content","id":"/content/97rviamdk8sorcopa3sr5botkn06oo7d","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"The world needs an international agency for artificial intelligence, say two AI experts","subheadline":"Artificial intelligence","datePublished":"2023-04-18T20:20:24Z","description":"Gary Marcus and Anka Reuel argue that global governance must be prioritised to address the risks of bias, misinformation or worse","image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230418_BID001.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":720},"__typename":"Media","promo":null}},{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/17/kaja-kallas-says-ukraine-is-giving-the-free-world-a-masterclass-on-cyber-defence","__typename":"URL"},"__typename":"Content","id":"/content/o2tq002mahu14nbvv3vok4es8vjgnrs7","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"Kaja Kallas says Ukraine is giving the free world a masterclass on cyber-defence","subheadline":"Digital warfare","datePublished":"2023-04-17T14:24:19Z","description":"The prime minister of Estonia on the need for better preparation against digital warfare","image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230415_BID001.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":720},"__typename":"Media","promo":null}},{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/13/intelligence-leaks-are-an-opportunity-as-well-as-a-threat-says-thomas-rid","__typename":"URL"},"__typename":"Content","id":"/content/qaa79ilcs2ed5anjv1ndlb8f9qo2caap","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"Intelligence leaks are an opportunity as well as a threat, says Thomas Rid","subheadline":"The Pentagon leaks","datePublished":"2023-04-13T13:08:46Z","description":"The scholar of spycraft says the private sector learns a lot from security breaches","image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230415_BID003.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":720},"__typename":"Media","promo":null}},{"url":{"canonical":"https://www.economist.com/by-invitation/2023/04/12/jonathan-powell-on-preparations-for-peace-making-in-ukraine","__typename":"URL"},"__typename":"Content","id":"/content/usclkoee8oauotgclq4agur5197evrsc","type":["Article","NewsArticle","AnalysisNewsArticle"],"headline":"Jonathan Powell on preparations for peace-making in Ukraine","subheadline":"Russia and Ukraine","datePublished":"2023-04-12T17:50:12Z","description":"Tony Blair’s former chief-of-staff says lessons from the Good Friday Agreement can help bring peace","image":{"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230415_BID002.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":720},"__typename":"Media","promo":null}}],"__typename":"HasPart"}}],"__typename":"Taxonomies"},"publication":[{"url":{"canonical":"https://www.economist.com/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/oq02trftu9mc92lsd5itom87ufgqp15q","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]},{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_AP.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["AF","AS","AU","BD","BT","BN","KH","CN","CK","FJ","GU","PF","HK","IN","ID","JP","KI","KP","KR","LA","MO","MY","MV","MH","FM","MN","MM","NR","NP","NC","NZ","PK","PG","PH","PN","SC","SG","SB","LK","TF","TW","TH","TO","TV","VU","VN","IO","CC","TL","HM","NU","NF","MP","PW","WS","CX","TK","WF"]},{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_UK.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["UK","GB","GG","IM","JE","AD","AL","AM","AX","AZ","BA","BG","BY","CH","CY","CZ","EE","FO","GE","GI","GL","HR","HU","IS","KG","KZ","LI","LT","LV","MC","MD","ME","MK","MT","NO","PL","RO","RS","RU","SI","SJ","SK","SM","TJ","TM","TR","UA","UZ","VA","IT","FR","ES","IE","AT","BE","DK","FI","DE","GR","LU","NL","PT","SE","BH","IR","IQ","IL","JO","KW","LB","OM","SA","SY","AE","PS","QA","YE","DZ","AO","BJ","BW","BF","BI","CM","CV","CF","TD","KM","CD","CI","DJ","EG","GQ","ER","ET","GA","GM","GH","GN","GW","KE","LS","LR","LY","MG","MU","MW","ML","MR","YT","MA","MZ","NA","NE","NG","RE","RW","SH","SS","ST","SN","SL","SO","ZA","SD","SZ","TZ","TG","TN","UG","EH","ZM","ZW","CG"]},{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_AP.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280},{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_UK.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280},{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/eu/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/4scc4vva7odlr6m76otihrom34b2lu80","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/ap/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/fqi3r1ipeqmp3sn7rnquv7getubmh3v2","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_AP.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["AF","AS","AU","BD","BT","BN","KH","CN","CK","FJ","GU","PF","HK","IN","ID","JP","KI","KP","KR","LA","MO","MY","MV","MH","FM","MN","MM","NR","NP","NC","NZ","PK","PG","PH","PN","SC","SG","SB","LK","TF","TW","TH","TO","TV","VU","VN","IO","CC","TL","HM","NU","NF","MP","PW","WS","CX","TK","WF"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_AP.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_AP.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/la/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/2q9c1n7p82uugfpdffl189mrkemql2f7","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/me/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/oebc7jcc10bin6t3e44svq590regi5bv","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/uk/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/qk3633vlq3r42orc70a3haatrqk3f45s","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_UK.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["UK","GB","GG","IM","JE","AD","AL","AM","AX","AZ","BA","BG","BY","CH","CY","CZ","EE","FO","GE","GI","GL","HR","HU","IS","KG","KZ","LI","LT","LV","MC","MD","ME","MK","MT","NO","PL","RO","RS","RU","SI","SJ","SK","SM","TJ","TM","TR","UA","UZ","VA","IT","FR","ES","IE","AT","BE","DK","FI","DE","GR","LU","NL","PT","SE","BH","IR","IQ","IL","JO","KW","LB","OM","SA","SY","AE","PS","QA","YE","DZ","AO","BJ","BW","BF","BI","CM","CV","CF","TD","KM","CD","CI","DJ","EG","GQ","ER","ET","GA","GM","GH","GN","GW","KE","LS","LR","LY","MG","MU","MW","ML","MR","YT","MA","MZ","NA","NE","NG","RE","RW","SH","SS","ST","SN","SL","SO","ZA","SD","SZ","TZ","TG","TN","UG","EH","ZM","ZW","CG"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_UK.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_UK.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}},{"url":{"canonical":"https://www.economist.com/na/printedition/2023-04-22","__typename":"URL"},"__typename":"Content","type":["PublicationIssue","RegionalIssue"],"headline":"WEEKLY EDITION: APR 22ND 2023","description":"","subheadline":"","datePublished":"2023-04-22T00:00:00Z","datePublishedString":"Apr 22nd 2023","id":"/content/588urv90n1p5co985p8os2oho9o1gj26","image":{"cover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","headline":"How to worry wisely about AI","width":1280,"height":1684,"regionsAllowed":["US","CA","PM","UM","AI","BL","BQ","BV","CW","GS","MF","SX","AG","AR","AW","BS","BB","BZ","BM","BO","BR","KY","CL","CO","CR","CU","DM","DO","EC","SV","FK","GF","GD","GP","GT","GY","HN","HT","JM","MQ","MX","MS","NI","PA","PY","PE","PR","KN","LC","VC","SR","TT","TC","UY","VE","VG","VI"]}],"main":{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1684},"squareCover":[{"url":{"canonical":"https://www.economist.com/media-assets/image/20230422_DE_SQ_US.jpg","__typename":"URL"},"__typename":"Content","width":1280,"height":1280}],"__typename":"Media"}}],"channel":{"tegID":"j53t6hsedat4l7rkbb1le98u73262sh5","__typename":"Content"},"_metadata":{"articleId":"/content/97rviamdk8sorcopa3sr5botkn06oo7d","tegID":"97rviamdk8sorcopa3sr5botkn06oo7d","title":"Artificial intelligence - The world needs an international agency for artificial intelligence, say two AI experts | By Invitation | The Economist","shareSnippet":"Artificial intelligence – The world needs an international agency for artificial intelligence, say two AI experts","headline":"The world needs an international agency for artificial intelligence, say two AI experts","section":"By Invitation","keywords":[],"author":["The Economist"],"url":"https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts","type":"Article","articleBody":"NEW GENERATIVE-AI tools like OpenAI’s ChatGPT, the fastest-growing consumer internet application of all time, have taken the world by storm. They have uses in everything from education to medicine and are astonishingly fun to play with. Although current AI systems are capable of spectacular feats they also carry risks. Europol has warned that they might greatly increase cybercrime. Many AI experts are deeply worried about their potential to create a tsunami of misinformation, posing an imminent threat to the American presidential election in 2024, and ultimately to democracy itself, by creating an atmosphere of total distrust. Scientists have warned that these new tools could be used to design novel, deadly toxins. Others speculate that in the long term there could be a genuine risk to humanity itself. \nOne of the key issues with current AI systems is that they are primarily black boxes, often unreliable and hard to interpret, and at risk of getting out of control. For example, the core technology underlying systems like ChatGPT, large language models (LLMs), is known to “hallucinate”, making up false statements. ChatGPT, for example, falsely accused a law professor of being involved in sexual harassment, apparently confused by statistical but irrelevant connections between bits of text that didn’t actually belong together. After an op-ed tried to clarify what had gone wrong, Bing Chat made a similar error, and attributed it to information in USA Today that the chatbot got completely backwards. \nThese systems can also be used for deliberate abuse, from disrupting elections (for example by manipulating what candidates appear to say or write) to spreading medical misinformation. In a recent analysis of GPT-4, OpenAI’s most advanced LLM, the company acknowledged 12 serious concerns—without providing firm solutions to any of them. \nIn the past year alone 37 regulations mentioning AI were passed around the globe; Italy went so far as to ban ChatGPT. But there is little global co-ordination. Even within some countries there is a hodge-podge, such as different state laws in America, or Britain’s proposal to eschew a central regulator, leaving oversight split among several agencies. An uneven, loophole-ridden patchwork is to no one’s benefit and safety. Nor should companies want to build a different AI model for each jurisdiction and face their own de novo struggle to navigate legal, cultural and social contexts. \nRead more from our special series on AI:\nLarge, creative AI models will transform lives and labour markets\nHow generative models could go wrong\nLarge language models’ ability to generate text also lets them plan and reason\n\n\nStill, there is plenty of agreement about basic responsible AI principles, such as safety and reliability, transparency, explainability, interpretability, privacy, accountability and fairness. And almost everyone agrees that something must be done—a just-published poll by the Centre for the Governance of AI found that 91% of a representative sample of 13,000 people across 11 countries agreed that AI needs to be carefully managed. \nIt is in this context that we call for the immediate development of a global, neutral, non-profit International Agency for AI (IAAI), with guidance and buy-in from governments, large technology companies, non-profits, academia and society at large, aimed at collaboratively finding governance and technical solutions to promote safe, secure and peaceful AI technologies. \nThe time for such an agency has come, as Google CEO Sundar Pichai himself said on April 16th. What might that look like? Each domain and each industry will be different, with its own set of guidelines, but many will involve both global governance and technological innovation. For example, people have long agreed that making employment decisions based on gender should be avoided, and have even come up with some measures in earlier, more interpretable AI, such as the interpretability requirements of the AI Bill of Rights proposed by the Biden administration. But in black-box systems like ChatGPT there is a wide variety of use cases with no current remedy. People might, for example, feed in a job candidate’s entire file and ask ChatGPT for a judgment, but we currently have no way to ensure that ChatGPT would avoid bias in its output. The kind of entity we envision would collaboratively address what to do about such “off-label” uses of chatbots and other policy questions, and at the same time develop technical tools for effective auditing. \nThe IAAI could likewise convene experts and develop tools to tackle the spread of misinformation. On the policy side, it could ask, for instance, how wide-scale spreading of misinformation might be penalised. On the technical side, the initial focus should be on developing automated or semi-automated tools for answering fundamental questions, such as “How much misinformation is out there?”, “How rapidly is its volume growing?” and “How much is AI contributing to such problems?” Existing technologies are better at generating misinformation than detecting it. Considerable technical innovation will be required, and of great public benefit, but may or may not be of sufficiently direct commercial interest – hence the need for independent support by an entity like the IAAI. \nTo take a third, very recent example, systems with names like AutoGPT and BabyAGI have been devised that allow amateurs to build complex and difficult-to-debug (or even fathom) assemblies of unreliable AI systems controlling other unreliable AI systems to achieve arbitrary goals—a practice that may or may not prove to be safe. As Marek Rosa, CEO of GOOD.Ai, put it, we need new technical ideas on “how to increase security (proactive defence) in a world where there are billions of AI agents…running in apps and servers, and we don’t know what they are talking about”, perhaps necessitating a kind of “antivirus [software] against AI agents”. A global alliance with top experts and researchers on call would be able to give swift and thoughtful guidance on such new developments. \nDesigning the kind of global collaboration we envision is an enormous job. Many stakeholders need to be involved. Both short-term and long-term risks must be considered. No solution is going to succeed unless both governments and companies are on board, and it’s not just them: the world’s publics need a seat at the table. \nFortunately, there is precedent for such global co-operation. At the end of the second world war, for example, nuclear weapons sparked deep fears and uncertainties about how the new technology would be used. As a response, 81 countries unanimously approved the International Atomic Energy Agency’s statute to “promote safe, secure and peaceful nuclear technologies”, with inspection rights. A different, softer kind of model, with less focus on enforcement, is the International Civil Aviation Organisation, in which member countries make their own laws but take counsel from a global agency. Getting to the right model, and making the right choices, will take time, wisdom and collaboration. \nThe challenges and risks of AI are, of course, very different and, to a disconcerting degree, still unknown. We know in hindsight that the internet might have been designed in better ways with more forethought. Earlier decisions about how to handle privacy and anonymity, for instance, might have ensured that there was less of a culture of trolling. We also know that early choices get locked in. Our decisions now are likely to have lasting consequences and must be made thoughtfully.\nGiven how fast things are moving, there is not a lot of time to waste. A global, neutral non-profit with support from governments, big business and society is an important start. ■\nGary Marcus is Emeritus Professor at NYU and was founder and CEO of Geometric Intelligence, a machine-learning company acquired by Uber. Anka Reuel is a PhD student in computer science at Stanford University and founding member of KIRA, a think-tank focusing on the promotion of responsible AI.","description":"Gary Marcus and Anka Reuel argue that global governance must be prioritised to address the risks of bias, misinformation or worse","ogDescription":"Gary Marcus and Anka Reuel argue that global governance must be prioritised to address the risks of bias, misinformation or worse","imageUrl":"https://www.economist.com/media-assets/image/20230418_BID001.jpg","imageHeight":720,"imageWidth":1280,"datePublished":"2023-04-18T20:20:24Z","dateModified":"2023-04-20T16:59:35Z","dateCreated":"2023-04-18T20:20:12Z","isPrintArticle":true,"printEdition":"2023-04-22T00:00:00Z","copyrightYear":2023,"dateline":"","inLanguage":"en","interactive":false,"scripts":[],"css":[]},"sectionArticles":[{"id":"/content/97rviamdk8sorcopa3sr5botkn06oo7d","publication":[{"id":"/content/oq02trftu9mc92lsd5itom87ufgqp15q","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/4scc4vva7odlr6m76otihrom34b2lu80","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/fqi3r1ipeqmp3sn7rnquv7getubmh3v2","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/2q9c1n7p82uugfpdffl189mrkemql2f7","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/oebc7jcc10bin6t3e44svq590regi5bv","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/qk3633vlq3r42orc70a3haatrqk3f45s","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"},{"id":"/content/588urv90n1p5co985p8os2oho9o1gj26","context":{"position":350.47,"__typename":"Content"},"__typename":"Content"}],"headline":"The world needs an international agency for artificial intelligence, say two AI experts","url":{"canonical":"https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts","__typename":"URL"},"__typename":"Content"},{"id":"/content/o2tq002mahu14nbvv3vok4es8vjgnrs7","publication":[{"id":"/content/oq02trftu9mc92lsd5itom87ufgqp15q","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/4scc4vva7odlr6m76otihrom34b2lu80","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/fqi3r1ipeqmp3sn7rnquv7getubmh3v2","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/2q9c1n7p82uugfpdffl189mrkemql2f7","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/oebc7jcc10bin6t3e44svq590regi5bv","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/qk3633vlq3r42orc70a3haatrqk3f45s","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"},{"id":"/content/588urv90n1p5co985p8os2oho9o1gj26","context":{"position":350.46,"__typename":"Content"},"__typename":"Content"}],"headline":"Kaja Kallas says Ukraine is giving the free world a masterclass on cyber-defence","url":{"canonical":"https://www.economist.com/by-invitation/2023/04/17/kaja-kallas-says-ukraine-is-giving-the-free-world-a-masterclass-on-cyber-defence","__typename":"URL"},"__typename":"Content"}]},"cp2Content":{},"statusCode":200,"paywallCheck":{"shouldDropPaywall":false},"featureFlags":["SF_SIGNPOSTING","SOURCEPOINT","ONBOARDING_NOTIFICATION","ONBOARDING_GROUP_NOTIFICATION","OPTIMIZELY_SELF_HOSTING","LAPSED_USER_NOTIFICATION","CP2","IN_THIS_REPORT","REGISTRANT_ONBOARDING","SAVED_STORIES_SWITCHOVER","ARTICLE_GIFTING_SWITCHOVER","SITEMAP","APP_PROMO_PAGE","SHOW_WEB_HEADS","CLOUDFLARE_IMAGE_FORMAT","NEXT_SCRIPT_THIRD_PARTIES"],"newsletters":{"newsletters":[{"code":"plot_twist","availableTo":["core"],"ident":"plot-twist","title":"Plot Twist","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Plot_Twist?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"plot-twist","hasPreview":true,"isNew":false,"description":"A weekly conversation about culture. Because culture is a serious business","promo":{"title":"Broaden your perspective with our weekly culture newsletter","description":"Exploring trends and connections across entertainment, the arts and politics","tagline":"Subscriber only"},"keywords":["Culture"],"priority":2,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"blighty","availableTo":["core"],"ident":"blighty","title":"Blighty","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Blighty?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"blighty","hasPreview":true,"isNew":false,"description":"Analysing the challenges facing Britain and what needs to be done to overcome them","promo":{"title":"Stay informed with our weekly Britain newsletter","description":"Analysing the challenges facing Britain and what needs to be done to overcome them","tagline":"Subscriber only"},"keywords":["Britain"],"priority":2,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"drum_tower","availableTo":["core"],"ident":"drum-tower","title":"Drum Tower","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/drumtower?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"drum-tower","hasPreview":true,"isNew":false,"description":"Understand what the world makes of China—and what China makes of the world","promo":{"title":"Stay informed with our weekly China newsletter","description":"Understand what the world makes of China—and what China makes of the world","tagline":"Subscriber only"},"keywords":["China"],"priority":2,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"the_bottom_line","availableTo":["core"],"ident":"the-bottom-line","title":"The Bottom Line","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/the_bottom_line?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"the-bottom-line","hasPreview":true,"description":"Your essential guide to global business and technology","promo":{"title":"Need to track the megatrends shaping business and technology?","description":"From supply chains to semiconductors, The Bottom Line newsletter has you covered","tagline":"Subscriber only"},"keywords":["Business"],"priority":2,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"espresso","availableTo":["espresso","core"],"ident":"the-world-in-brief","title":"The World in Brief","frequency":"Daily","imageUrl":"https://myaccount.economist.com/file-asset-public/the_world_in_brief?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"the-world-in-brief","hasPreview":true,"description":"Catch up quickly on the global stories that matter","promo":{"title":"Catch up quickly on the stories that matter","description":"Sign up to enjoy a mind-expanding mix of stories, delivered six days a week","tagline":"Subscriber only"},"keywords":[],"priority":-1,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"cover_story","availableTo":["core"],"ident":"cover-story","title":"Cover Story","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Cover_Story?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"cover-story","hasPreview":true,"description":"A behind-the-scenes look at how we chose and designed this week’s cover","promo":{"title":"How we chose this week’s cover image","description":"Delivered to your inbox every weekend","tagline":"Subscriber only"},"keywords":[],"priority":3,"isKeywordFallback":false,"onboardingPreSelect":true,"live":true},{"code":"checks_and_balance","availableTo":["core"],"ident":"checks-and-balance","title":"Checks and Balance","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Checks_and_Balance?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"checks-and-balance","hasPreview":true,"description":"Exclusive insight from our correspondents in America","promo":{"title":"Exclusive insight and reading recommendations from our correspondents in America","description":"Delivered to your inbox every week","tagline":"Subscriber only"},"keywords":["United States","United States Senate","Republican Party","Donald Trump","Joe Biden","Democratic Party","Executive Office of the President of the United States"],"priority":6,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"simply_science","availableTo":["core"],"ident":"simply-science","title":"Simply Science","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Simply_Science2?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"simply-science","hasPreview":true,"description":"A weekly fix of our mind-expanding science coverage","promo":{"title":"Curious about the world? Enjoy a weekly fix of our mind-expanding science coverage","description":"Delivered to you every week","tagline":"Subscriber only"},"keywords":["science and technology","Science \u0026 technology","biology","astronomy","philosophy","chemistry","diseases and conditions","genetics","cancer","medicine","physics"],"priority":4,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"climate_change","availableTo":["core"],"ident":"the-climate-issue","title":"The Climate Issue","frequency":"Fortnightly","imageUrl":"https://myaccount.economist.com/file-asset-public/Climate_issue?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"the-climate-issue","hasPreview":true,"description":"Climate-change analysis that you won’t read elsewhere in \u003cem\u003eThe Economist\u003c/em\u003e","promo":{"title":"Climate-change analysis that you won’t read elsewhere in \u003cem\u003eThe Economist\u003c/em\u003e","description":"Delivered to your inbox every fortnight","tagline":"Subscriber only"},"keywords":["energy industry","migration of people","weather","energy and resource","plant","synthetic and plastic chemicals","forestry and timber","climate change","global warming","environment","environmental politics","environmental pollution"],"priority":5,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"money_talks","availableTo":["core"],"ident":"money-talks","title":"Money Talks","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/money_talks?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"money-talks","hasPreview":true,"description":"Expert analysis of the biggest stories in economics and markets","promo":{"title":"Expert analysis of the biggest stories in economics and markets","description":"Delivered to your inbox every week","tagline":"Subscriber only"},"keywords":["Finance \u0026 economics"],"priority":100,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"off_the_charts","availableTo":["core"],"ident":"off-the-charts","title":"Off the Charts","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/Off_the_charts2?oid=00D3z000002JvyiEAC","tagline":"Subscriber only","slug":"off-the-charts","hasPreview":true,"description":"Taking you behind the scenes of our data journalism","promo":{"title":"Taking you behind the scenes of our data journalism","description":"Directly to your inbox every week","tagline":"Subscriber only"},"keywords":["Graphic detail"],"priority":99,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"the_extraordinary_story","availableTo":["anonymous","registered","espresso","core"],"ident":"the-extraordinary-story","title":"The Extraordinary Story","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/the_extraordinary_story?oid=00D3z000002JvyiEAC","slug":"the-extraordinary-story","hasPreview":true,"description":"Long reads and life from \u003cem\u003e1843 magazine\u003c/em\u003e","promo":{"title":"Long reads and life from \u003cem\u003e1843 magazine\u003c/em\u003e","description":"Delivered to your inbox every weekend","tagline":""},"keywords":["1843 magazine"],"priority":100,"isKeywordFallback":false,"onboardingPreSelect":false,"live":true},{"code":"te_today","availableTo":["anonymous","registered","espresso","core"],"ident":"the-economist-today","title":"The Economist today","frequency":"Daily","imageUrl":"https://myaccount.economist.com/file-asset-public/The_Economist_Today?oid=00D3z000002JvyiEAC","slug":"the-economist-today","hasPreview":true,"description":"The very best of our journalism, handpicked for you each weekday","promo":{"title":"Handpicked stories, in your inbox","description":"A daily newsletter with the best of our journalism","tagline":""},"keywords":[],"priority":0,"isKeywordFallback":true,"onboardingPreSelect":false,"live":true},{"code":"te_this_week","availableTo":["anonymous","registered","espresso","core"],"ident":"the-economist-this-week","title":"The Economist this week","frequency":"Weekly","imageUrl":"https://myaccount.economist.com/file-asset-public/The_Economist_This_Week?oid=00D3z000002JvyiEAC","slug":"the-economist-this-week","hasPreview":true,"description":"Highlights from the latest weekly issue, introduced by our editor","promo":{"title":"Highlights from the latest weekly issue, introduced by our editor","description":"Directly to your inbox every week","tagline":""},"keywords":[],"priority":2,"isKeywordFallback":false,"onboardingPreSelect":true,"live":true}],"status":"ok"}}},"page":"/[...slug]","query":{"slug":["by-invitation","2023","04","18","the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts"]},"buildId":"etnhbTFBUJ-889VaF-7i6","assetPrefix":"/engassets","isFallback":false,"gip":true,"appGip":true,"scriptLoader":[]}