###### The easy problem is not so easy
# Thousands of species of animals probably have consciousness 
##### A group of scientists are trying to track down how it works in the brain 
![image](images/20230701_STD001.jpg) 
> Jun 28th 2023 
The Amygdaloids sound like one of the aliens-of-the-week from “Star Trek”. In fact, they are a rock band from New York University (NYU), whose singer, lead guitarist and moving spirit is Joseph LeDoux. Dr LeDoux is one of the world’s top authorities on the amygdalas, a pair of almond-shaped structures in the brain that are responsible, among other things, for generating fear in response to threats. But he is also president of the Association for the Scientific Study of Consciousness (ASSC), which held its 26th meeting at NYU between June 22nd and 25th. 
The Amygdaloids were merely the warm-up act. Top of the bill was the announcement of the result of a so-called “adversarial collaboration” between proponents of two hypotheses about the nature of consciousness. This involved running a series of experiments, , to determine which (if either) of them is correct. 
And there was more at stake than mere science. In 1998 David Chalmers and Christof Koch, a pair of up-and-coming consciousness researchers who are now doyens of the field, made a bet. They wagered that, within 25 years, the so-called neural correlates of consciousness (the nerve cells in which consciousness is generated) would be clear (Dr Koch’s position), or would not be (Dr Chalmers’s). Both researchers agreed that the adversarial experiment would also determine the outcome of their bet.
Consciousness is one of the few natural phenomena which remain thoroughly enigmatic. Physics has mysteries, for sure—one of the biggest is how to reconcile quantum mechanics with the theory of relativity. But physicists do have some sense of where they are going, and what they are dealing with. People studying consciousness, less so.
Deep thoughts
Their difficulty was crystallised by Dr Chalmers, who is now at NYU, in 1994. He split the study of consciousness into the “easy problem” and the “hard problem”. The easy problem is to pinpoint which mechanisms in the brain lead to conscious experience. It is not in fact that easy—but it should at least be tractable. The  concerns the subjective experiences which philosophers call “qualia”. As Dr Chalmers, himself a philosopher rather than an experimentalist, put it: “Why is it that when our cognitive systems engage in visual and auditory information-processing, we have a visual or auditory experience?” 
The big experiment tried to tackle the easy problem. As Rocco Gennaro, a philosopher at the University of Southern Indiana, outlined, the field of consciousness has no shortage of theories. Among those he mentioned were substance dualism, epiphenomenalism, eliminative materialism, multiple drafts theory, attended intermediate level theory, sensorimotor theory, panpsychism and emergentism. Two, though, have muscled their way to the front. One is called Integrated Information Theory (IIT); the other, Global Neuronal Workspace Theory (GWNT). It was between these ideas that the experiment was intended to adjudicate. 
That merely connecting up a lot of nerve cells is not enough to create consciousness is well known. Some people, for example, are born without a cerebellum, a structure which contains half the brain’s nerve cells but takes up only 10% of its volume. Though these individuals may have problems with everything from balance to emotional engagement, they are fully conscious. What seems to matter is exactly how the cells are connected—and especially, many researchers believe, how feedback loops between them work. 
IIT attempts to capture that mathematically, using a value called phi to measure the level of integration brought about by such feedback loops. GNWT does not depend on feedback loops in this way. It involves the shuffling of data between a central-processing short-term memory area, where they are thought to enter conscious perception, and peripheral areas that process things such as perception, attention, motor-control and long-term memory.
![image](images/20230701_STD002.jpg) 

IIT suggests conscious activity is generated towards the back of the brain, in the sensory areas of the cerebrum, particularly the visual cortex. Advocates of GWNT, by contrast, reckon consciousness arises at the front of the cerebrum. This contains the prefrontal cortex, which is, roughly speaking, the brain’s executive centre. The front and back of the cerebral cortex have different micro-anatomical structures as well as different jobs. Supporters of IIT argue that only the back part has the connective architecture needed to support a high enough phi for consciousness. Partisans of GNWT, meanwhile, think that the processing they envisage as necessary for consciousness is best carried out by the columns of nerve cells characteristic of the front of the cortex. It was this distinction which underpinned the experiments. 
In the event, those hoping for a definitive victory were disappointed, though IIT seemed to have won on points. (Some data remain to be analysed, so this judgment may yet be strengthened or weakened.) But what everyone did agree was that no clear neural correlates of consciousness had been seen—making Dr Chalmers the winner of the 25-year-old bet. Bottles of wine duly changed hands.
It is just possible, however, that the experiment was asking the wrong question. Asger Kirkeby-Hinrup of Lund University, in Sweden, pointed out that, just as heat can be generated in many ways, perhaps the same might be true of consciousness. If so—and Dr Kirkeby-Hinrup said he only half believes it himself—then methods like those used in the adversarial collaboration may never give clean results.
Having more than one way of generating consciousness could also help those investigating how consciousness can have various states in humans (dreaming, for example, is a conscious state, but a rather different one from being awake), and to what extent other animals are conscious (different groups might have different mechanisms). It might also bear on the question of how to design conscious artificial intelligence (AI).
When it comes to animals, most researchers in the field agree that three groups (and probably only three) display behaviour that is complex enough for it to be worthwhile asking if they are conscious. These are vertebrates, cephalopods and arthropods. All three had their champions at the meeting.
Many creatures great and small
Oryan Zacks at Tel Aviv University and her colleagues study vertebrate phylogeny and neuroanatomy. They have concluded that the common ancestor of all jawed vertebrates, which lived over 400m years ago during the Silurian period, had a brain which could support the neural architecture required by GWNT. That would bring about 60,000 modern species, including mammals, lizards, amphibians and most fish, into the consciousness camp.
Peter Godfrey-Smith of the University of Sydney championed the cephalopod cause with a behavioural argument rather than an anatomical one. He pointed to experiments conducted on octopuses showing the animals’ sophisticated reactions to aversive stimuli, as well as some beautiful video of them playing with cameras they had picked up from the seabed.
That leaves arthropods. Here, the arguments are more equivocal. Daria Zakharova of the London School of Economics made a case for consciousness in a genus of hunting spiders called . Experiments she and others have conducted suggest these animals, which have good vision, plan in advance how to get to prey, and can work out beforehand if this is impossible. Andrew Crump, a colleague of Ms Zakharova’s, meanwhile, presented a less convincing case for bumblebees being worthy of further investigation on the basis of some experiments using sugar water as a reward and quinine as a punishment.
As to conscious AI, Yoshua Bengio of the University of Montreal, a pioneer of the modern deep-learning approach to AI, told the meeting he believes it might be possible to achieve consciousness in a machine using the global-workspace approach. He explained the advantages this might bring, including being able to generalise results with fewer data than the present generation of enormous models require. His fear, though, is that someone will build a self-preservation instinct into a conscious AI, which could result in its running out of control. Indeed, he was a signatory to an open letter released in March calling for a pause on giant AI experiments.
At the moment, conscious AI remains the stuff of science fiction. But ten years ago, so was the idea of a machine which could apparently hold an intelligent conversation. From a Silurian fish to  was a long journey. The next step on consciousness’s path looks like being far faster than that. ■

